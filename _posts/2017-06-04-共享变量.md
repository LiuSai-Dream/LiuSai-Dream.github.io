## 共享变量
通过`tf.variable_scope()`和`tf.get_variable()`来共享大量的变量。

### 问题
当模型变得很复杂，变量的共享成为重点。

共享变量通常的做法是在其他代码中创建，然后传递到需要变量的函数中。
```
variables_dict = {
    "conv1_weights": tf.Variable(tf.random_normal([5,5,32,32]), name="conv1_weigths")
    "conv1_biases": tf.Variable(tf.zeros([32]),name="conv1_biases")
}

def my_image_filter(input_images, variables_dict):
    conv1 = tf.nn.conv2d(input_images, variables_dict["conv1_weigths"], strides=[1,1,1,1], padding='SAME')
    relu1 = tf.nn.relu(conv1 + variables_dict["conv1_biases"])

    conv2 = tf.nn.conv2d(relu1, variables_dict["conv2_weights"], strides=[1,1,1,1], padding='SAME')
    return tf.nn.relu(conv2 + variables_dict["conv2_biases"]

result1 = my_image_filter(image1, variables_dict)
result2 = my_image_filter(image2, variabels_dict)
```

尽管这样做很方面，却有如下弊端:
- 构建图的代码一定要书写变量的名称、类型、和形状
- 当代码改变时，调用者可能会创建或多或少的其他变量

解决该问题的一个方式是使用类来创建一个模型，由类来管理需要的变量。
tensorflow提供了更加轻量级的*Variable Scope*机制，它允许在构建图的时候轻松的共享命名变量。

### Variable Scope 例子
Variable Scope机制包括两个主要的函数：
- `tf.get_variable(<name>, <shape>, <initializer>)`：创建或者返回给定名称的变量
- `tf.variable_scope(<scope_name>)`：管理传递到`tf.get_variable()`的命名空间

函数`tf.get_variables()`用来代替`tf.Variables()`得到或者创建一个变量。它使用*initializer*而不是直接传递值。一些initializers的例子：
- `tf.constant_initializer(value)` 初始化所有值为给定的值
- `tf.random_uniform_initializer(a, b)` 使用[a, b]之间的值均匀的初始化
- `tf.random_normal_initializer(mean, stddev)`使用给定的mean和stddev分布来初始化

使用`tf.get_variables()`来重构之前的函数：
```
def conv_relu(input, kernel_shape, bias_shape):
    weights = tf.get_variables("weights", kernel_shape, initializer=tf.random_normal_initializer())

    biases = tf.get_variables("biases", bias_shape, initializer=tf.constant_initializer(0.0))

    conv = tf.nn.conv2d(input, weights, stripes=[1,1,1,1], padding='SAME')

    return tf.nn.relu(conv + biases)
```
函数中使用了变量名称`weights`和`biases`。需要在`conv1`和`conv2`里面使用它们，但是需要不同的名称。
这就是`tf.variable_scope()`发挥作用的地方：它为变量加上命名空间。

```
def my_image_filter(input_image):
    with tf.variable_scope("conv1")"
        relu1 = conv_relu(input_image, [5, 5, 32, 32],[32])
    
    with tf.variable_scope("conv2"):
        return conv_relu(relue1, [5, 5, 32, 32], [32])
```

通过`scope.reuse_variables()`来重用变量

### Variable Scope是如何工作的？
理解**tf.get_variable()**
使用`tf.get_variable`的通常方式是：
`v = tf.get_variable(name, shape, dtype, initializer)`
根据调用它的scope可分为两种情况：
- 1. 为创建新的变量使用`tf.get_variable_scope().reuse == False`设置了scope。
这种情况下会新建`v`，该变量的全名称由当前变量的scope名称 + 给定的名称组成。
```
with tf.variable_scope("foo"):
    v = tf.get_variable("v", [1])
assert v.name == "foo/v:0"
```

- 2. 设置`tf.get_variable_scope().resue == True`来重用变量
这种情况下，首先会根据scope name + 给定名称 查找变量，如果找到则返回，否则抛出异常。

### `tf.variable_scope`的基础
variable scope的主要作用是当作变量名称的前缀，以及一个重用标识来区别上述两种情况。内嵌的variable scope会进行拼接。

```
with tf.variable_scope("foo"):
    with tf.variable_scope("bar"):
        v = tf.get_variable("v", [1])
assert v.name == "foo/bar/v:0"
```
可以使用`tf.get_variable_scope()`来获取当前的variable scope。可通过`tf.get_variable_scope().reuse_variables()`来设置`resue`标识为`True`。

```
with tf.variable_scope("foo"):
    v = tf.get_variable("v", [1])
    tf.get_variable_scope().resue_variables()
    v1 = tf.get_variable("v", [1])
assert v1 is v
```

注意，不能设置resue标识为false。但是可以离开正在使用的variable scope。
```
with tf.variable_scope("root"):
    # 刚开始，reuse是关闭状态
    assert tf.get_variable_scope().resue == False
    with tf.variable_scope("foo"):
        assert tf.get_variable_scope().reuse == False
    with tf.variable_scope("foo", resure=True):
        assert tf.get_variable_scope().resue == True
        with tf.variable_scope("bar"):
            # resue具有继承行为
            assert tf.get_variable_scope().reuse == True
    assert tf.get_variable_scope().reuse == False
```

### 捕捉variable scope
上面的例子中使用字符串来共享variable scope。然而在复杂的环境下，传递VariableScope对象会更加有用。
```
with tf.variable_scope("foo") as foo_scope:
    v = tf.get_variable("v", [1])
with tf.variable_scope(foo_scope):
    w = tf.get_variable("w", [1])
with tf.variable_scope(foo_scope, reuse=True):
    v1 = tf.get_variable("v", [1])
    w1 = tf.get_variable("w", [1])
assert v1 is v
assert w1 is w
```

### 在variable scope中初始化
使用`tf.get_variable()`允许




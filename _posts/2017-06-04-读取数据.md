## 读取数据
有三种读取数据的方法：
- Feeding：Python 代码在每轮迭代时提供数据
- 从文件中读取：从文件中读取
- 预加载数据：使用常量或者变量保存所有数据(小数据集)

### Feeding
Tensorflow的feed机制允许向图中的任意张量注入数据。这样就可以把数据直接的放入图中。

通过调用run(), eval()向 `feed_dict`的参数传递数据。
```
with tf.Session():
    input = tf.placeholder(tf.float32)
    classifier = ...
    print(classifier.eval(feed_dict = {input: my_python_preprocessing_fn()}))
```

当使用feed数据替换任意的张量，最好的实践就是使用`tf.placeholder`节点。`placeholder`就是为了feeds而生。若placeholder没有值就使用会发生错误。

### 从文件读取数据
从文件读取数据的经历的阶段：
1. 文件名称列表
2. （可选）文件名称洗牌
3. （可选）迭代限制
4. 文件名称队列
5. 文件格式相对应的读取器
6. 单条记录的解码器
7. （可选）预处理
8. 样例队列

#### 文件名称，洗牌，和迭代限制
可以使用常量`["file0", "file1"]`或者`[("file%d" % i) for i in range(2)]`或者`tf.train.match_filenames_once`

把文件名列表传递给`tf.train.string_input_producer`函数，该函数会创建一个FIFO队列保存文件名。

`string_input_producer`有洗牌和迭代的参数。queue runner把全部的文件名增加到队列一个迭代一次。洗牌程序提供了均匀的采样，这样样本就不会过采样或者低采样。

queue runner与读取器运行在不同的线程中，因此洗牌和入队操作不会阻塞读取器。

#### 文件格式
读取器输出记录的标识和一个常量字符串值。使用一个或者多个解码器来转换记录得到一个样本。

[详见](https://www.tensorflow.org/programmers_guide/reading_data)

### 预处理

### 批处理






















